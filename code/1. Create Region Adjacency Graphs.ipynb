{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Images into a Region Adjacency Graph\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "1. **skimage**\n",
    "  - for creating labelled components from the image (skimage.measure)\n",
    "  - for finding centroid of each label (skimage.measure)\n",
    "  - converting the labelled image into a RAG (skimage.future.graph)\n",
    "  \n",
    "2. **numpy**\n",
    "  - image array manipulation operations\n",
    "  \n",
    "3. **pickle**\n",
    "  - dumping the graphs in a file\n",
    "  \n",
    "4. **tqdm**\n",
    "  - for progress bars\n",
    "\n",
    "5. **cv2**\n",
    "  - create video files\n",
    "\n",
    "6. **networkx**\n",
    "  - for visualizing the graphs\n",
    "7. **os**\n",
    "  - saving images and videos\n",
    "8. **scipy**\n",
    "  - for developing kdtree to find lenght of shared boundary\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure, io, draw\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.future import graph\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import networkx as nx\n",
    "import os\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.set_cmap('gray')\n",
    "import networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw RAG edges and nodes over the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_edges(img, rag):\n",
    "    edge_img = img.copy() # to avoid modifying the original image\n",
    "    for edge in rag.edges:\n",
    "        # get the node pair for the edge\n",
    "        node_1, node_2 = edge\n",
    "        \n",
    "        # get the cordinated of the centroid of the node\n",
    "        x1, y1 = map(int, rag.nodes[node_1]['centroid'])\n",
    "        x2, y2 = map(int, rag.nodes[node_2]['centroid'])\n",
    "        \n",
    "        # draw the line joining the centroid of the 2 nodes\n",
    "        line_x, line_y = draw.line(x1,y1,x2,y2)\n",
    "        edge_img[line_x, line_y] = 127\n",
    " \n",
    "    return edge_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_nodes(img, rag):\n",
    "    node_img = img.copy() # to avoid modifying the original image\n",
    "    for node in rag.nodes(data=True):\n",
    "        \n",
    "        # get the coordinates of the centroid of the node\n",
    "        node_x, node_y = node[1]['centroid']\n",
    "        \n",
    "        # draw the circle at the centroid of the node\n",
    "        circle_x, circle_y = draw.circle(node_x, node_y, 2)\n",
    "        node_img[circle_x-1, circle_y-1] = 127\n",
    " \n",
    "    return node_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save graph overlay images\n",
    "Create output images containing the original image, labeled_image and graph overlayed over labeled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_overalay_graph_images(img, label_img, graph_image, img_name, combined=True):\n",
    "    \"\"\"\n",
    "    Style 1 has 3 images stacked over each other. \n",
    "    The original image, the label image(where each blob has a different label) \n",
    "    and graph overlay image.\n",
    "    Args:\n",
    "        img: original grayscale image\n",
    "        label_img: labelled_image\n",
    "        graph_img: label_img with graph pverlay on it\n",
    "        img_name: name of tghe image\n",
    "        combined: store each trajectory images in a\n",
    "                  separate folder if False. Default=True.\n",
    "    Returns:\n",
    "        Boolean describing the success of the operation\n",
    "    \"\"\"\n",
    "    #combined_img = np.concatenate([img,label_img,graph_img], axis=0)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    # plot the original image\n",
    "    ax = fig.add_subplot(3, 1, 1)\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.set_title(\"Original Image\")\n",
    "    \n",
    "    # Plot the labeled Image\n",
    "    ax = fig.add_subplot(3, 1, 2)\n",
    "    ax.imshow(label_img, cmap=\"nipy_spectral\")\n",
    "    ax.set_title(\"Labelled Image\")\n",
    "\n",
    "    # Plot the Graph Overlay Image\n",
    "    ax = fig.add_subplot(3, 1, 3)\n",
    "    ax.imshow(graph_img, cmap=\"nipy_spectral\")\n",
    "    ax.set_title(\"Graph Overlay Image\")\n",
    "    \n",
    "    trajectory_names = {0:\"BR0.5-CHI2.4\",\n",
    "                            1:\"BR0.5-CHI2.6\",\n",
    "                            2:\"BR0.5-CHI2.8\",\n",
    "                            3:\"BR0.5-CHI3.0\",\n",
    "                            4:\"BR0.52-CHI2.4\",\n",
    "                            5:\"BR0.52-CHI2.6\",\n",
    "                            6:\"BR0.52-CHI2.8\",\n",
    "                            7:\"BR0.52-CHI3.0\",\n",
    "                            8:\"BR0.54-CHI2.4\",\n",
    "                            9:\"BR0.54-CHI2.6\",\n",
    "                            10:\"BR0.54-CHI2.8\",\n",
    "                            11:\"BR0.54-CHI3.0\",\n",
    "                            12:\"BR0.56-CHI2.4\",\n",
    "                            13:\"BR0.56-CHI2.6\",\n",
    "                            14:\"BR0.56-CHI2.8\",\n",
    "                            15:\"BR0.56-CHI3.0\"}\n",
    "    trajectory_name = trajectory_names[int(img_name)//80]\n",
    "    title = f\"{trajectory_name} #{int(img_name)%80} ({img_name})\"\n",
    "    \n",
    "    fig.suptitle(title, fontsize=15, y=0.03)    \n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "    \n",
    "    \n",
    "    if combined:\n",
    "        plt.savefig(os.path.join(\"../outputs/graph_overlay_combined_images/\",img_name+\".jpg\"))\n",
    "    else:\n",
    "        plt.savefig(os.path.join(\"../outputs/graph_overlay_individual_trajectory_images/\",trajectory_name,img_name+\".jpg\"))\n",
    "    plt.close()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save graph videos\n",
    "Create a video of the saved images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_overalay_graph_video(source_dir, target_dir):\n",
    "    \"\"\"\n",
    "    Find all the images in a given \n",
    "    directory and create a video of them.\n",
    "    Args:\n",
    "        dir: path to the directory where all the images\n",
    "             are stored\n",
    "    \"\"\"\n",
    "    # read all the images from the source directory\n",
    "    source_dir += \"/*.jpg\" #asuming files are always written in jpg\n",
    "    imgs = io.imread_collection(source_dir, conserve_memory=True)\n",
    "    \n",
    "    # create a video writer in the target location\n",
    "    height, width, layers = imgs[0].shape\n",
    "    size = (width,height)\n",
    "    target_dir += \"/graph_overlay.avi\"\n",
    "    out = cv2.VideoWriter(target_dir,cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "    \n",
    "    # write the frames to the video writer \n",
    "    for img in imgs:\n",
    "        out.write(img)\n",
    "        out.write(img)\n",
    "    out.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save networkx graph visualization images\n",
    "Graphs created using networkx's draw_networkx function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph_visualization_images(graphs, combined=True):\n",
    "    \"\"\"\n",
    "    Save graph visualizations as images.\n",
    "    Args:\n",
    "        graphs: list of graphs to be visualized\n",
    "        combined: if False, directory name will\n",
    "                  be determined based on index number \n",
    "                  of the graph. Default=True.\n",
    "    \"\"\"\n",
    "    \n",
    "    for graph_num,gg in enumerate(tqdm(graphs)):\n",
    "        \n",
    "        fig,axes = plt.subplots()\n",
    "        \n",
    "        # setting node size\n",
    "        node_size = [i[1]['area'] for i in gg.nodes(data=True)]\n",
    "        sum_node_size = sum(node_size)\n",
    "        node_size_normalized = [(i/sum_node_size)*5000 for i in node_size]\n",
    "        \n",
    "        # setting node color\n",
    "        node_color = []\n",
    "\n",
    "        for i in gg.nodes(data=True):\n",
    "            current_color = i[1]['color']\n",
    "            if current_color == 1:\n",
    "                # this is white\n",
    "                # set to light grey\n",
    "                node_color.append(np.array([0.7,0.7,0.7]))\n",
    "            elif current_color == 0:\n",
    "                # this is black\n",
    "                # set to dark grey\n",
    "                node_color.append(np.array([0.3,0.3,0.3]))\n",
    "            else:\n",
    "                # this should never happen\n",
    "                print(\"Unknown color of node.\")\n",
    "        \n",
    "        # setting node label\n",
    "        node_labels = {}\n",
    "        for index, size in enumerate(node_size):\n",
    "            node_labels[index+1] = size\n",
    "            \n",
    "        # create the graph and save it\n",
    "        aa = nx.draw_kamada_kawai(gg, \n",
    "                             node_size   = node_size_normalized, \n",
    "                             node_color  = node_color,\n",
    "                             edgecolors  = 'k',\n",
    "                             labels      = node_labels,\n",
    "                             with_labels = True,\n",
    "                             ax          = axes)\n",
    "        \n",
    "        trajectory_names = {0:\"BR0.5-CHI2.4\",\n",
    "                            1:\"BR0.5-CHI2.6\",\n",
    "                            2:\"BR0.5-CHI2.8\",\n",
    "                            3:\"BR0.5-CHI3.0\",\n",
    "                            4:\"BR0.52-CHI2.4\",\n",
    "                            5:\"BR0.52-CHI2.6\",\n",
    "                            6:\"BR0.52-CHI2.8\",\n",
    "                            7:\"BR0.52-CHI3.0\",\n",
    "                            8:\"BR0.54-CHI2.4\",\n",
    "                            9:\"BR0.54-CHI2.6\",\n",
    "                            10:\"BR0.54-CHI2.8\",\n",
    "                            11:\"BR0.54-CHI3.0\",\n",
    "                            12:\"BR0.56-CHI2.4\",\n",
    "                            13:\"BR0.56-CHI2.6\",\n",
    "                            14:\"BR0.56-CHI2.8\",\n",
    "                            15:\"BR0.56-CHI3.0\"}\n",
    "        \n",
    "        title = trajectory_names[graph_num//80]+f\" #{graph_num%80} ({graph_num})\"\n",
    "        plt.title(title, y=-0.1)\n",
    "        if combined:\n",
    "            target_dir = f\"../outputs/graph_visualizations_combined/{title}.jpg\"\n",
    "        else:\n",
    "            target_dir = f\"../outputs/graph_visualizations_individual_trajectory/{trajectory_names[graph_num//80]}/{title}.jpg\"\n",
    "        plt.savefig(target_dir, format=\"JPG\")\n",
    "        plt.cla()\n",
    "        plt.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Region Adjacency Graph (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "1. Read the image, convert to grescale and thresh\n",
    "2. Assign labels to every black and white region(blob).\n",
    "3. Generate the Region Adjacency Graph(RAG).\n",
    "4. Add other attributes to the labels such as node area, color and centroid.\n",
    "5. Add weight of edges based on length of boundary shared between the 2 regions\n",
    "\n",
    "*Adaptive thresholding is not a good idea here because we need a constant threshold for all images as we will be calculating similarities in consecutive threshed images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fef9ea6775946bcaf66ea52bd1951df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1280.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read all the images\n",
    "img_filenames = [\"../outputs/images/\"+str(i)+\".jpg\" for i in range(1,1281)]\n",
    "imgs = io.imread_collection(img_filenames, conserve_memory=True)\n",
    "\n",
    "graphs = []\n",
    "kdtree = {}\n",
    "for index,img in enumerate(tqdm(imgs), start=0):\n",
    "    \n",
    "    # convert to grayscale and threshold\n",
    "    gray_img = rgb2gray(img)\n",
    "    thresh_img = gray_img > 127\n",
    "\n",
    "    # generate disinct labels for every region\n",
    "    # background set to -1 so that black blobs \n",
    "    # do not neglected and are assigned a label\n",
    "    label_img = measure.label(thresh_img, background=-1)\n",
    "\n",
    "    # generate the Region Adjacency Graph\n",
    "    rag = graph.RAG(label_img)\n",
    "    \n",
    "    # RAG doesn't add a node if there is only \n",
    "    # one label in label_image\n",
    "    if len(np.unique(label_img)) == 1:\n",
    "        rag.add_node(1)\n",
    "            \n",
    "    # add centroid, area and color attributes \n",
    "    # to each node using regionprops\n",
    "    regions = measure.regionprops(label_img, thresh_img)\n",
    "    for region in regions:\n",
    "        rag.nodes[region['label']] ['area'] = region['area']\n",
    "        rag.nodes[region['label']] ['color'] = region['mean_intensity']\n",
    "        rag.nodes[region['label']] ['centroid'] = region['centroid']\n",
    "        rag.nodes[region['label']] ['perimeter'] = region['perimeter']\n",
    "        # will be used to count the number pixels shared on the boundary of 2 regions\n",
    "        kdtree[region['label']] = KDTree(region.coords)\n",
    "    \n",
    "    # add weight of edges\n",
    "    # weight = number of neghbouring pixels \n",
    "    # of the two regions/nodes\n",
    "    for edge in rag.edges:\n",
    "        node1, node2 = edge\n",
    "        rag[node1][node2]['weight'] = kdtree[node1].count_neighbors(kdtree[node2], 1)\n",
    "    \n",
    "    \n",
    "        \n",
    "    #graph_img = draw_edges(draw_nodes(label_img, rag), rag)\n",
    "    \n",
    "    #generate_overalay_graph_images(img, label_img, graph_img, str(index))\n",
    "    #generate_overalay_graph_images(img, label_img, graph_img, str(index), combined=False)\n",
    "\n",
    "    graphs.append(rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.82842712474619"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions[0].perimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate video of all points combined and individual trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_overalay_graph_video(\"../outputs/graph_overlay_combined_images/\", \n",
    "                              \"../outputs/graph_overlay_combined_videos/\")\n",
    "\n",
    "# write the code for indivisual trajectories if it is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genrate Networkx visualizations for each RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4110a4a0ad4e7cb86aa461eccb1fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1280.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_graph_visualization_images(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump graph representations to be used elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(graphs, open('../outputs/pickle/graphs.file', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
